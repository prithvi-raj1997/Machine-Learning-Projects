{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib and seaborn for visuilization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Display all the columns of the dataframe\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "\n",
    "# No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data after preprocessing: (49999, 45)\n",
      "shape of amenities train data after preprocessing: (49999, 130)\n",
      "shape of test data after preprocessing: (24111, 44)\n",
      "shape of amenities test data after preprocessing: (24111, 130)\n"
     ]
    }
   ],
   "source": [
    "# Read  data into dataframe\n",
    "file_train=r'D:\\Deloitte\\train.csv'\n",
    "file_train_amenities=r'D:\\Deloitte\\amenities_train.csv'\n",
    "file_test=r'D:\\Deloitte\\test.xlsx'\n",
    "file_test_amenities=r'D:\\Deloitte\\amenities_test.xlsx'\n",
    "\n",
    "ab_train=pd.read_csv(file_train)\n",
    "amenities_train=pd.read_csv(file_train_amenities)\n",
    "ab_test=pd.read_excel(file_test)\n",
    "amenities_test=pd.read_excel(file_test_amenities)\n",
    "\n",
    "# Returns the number of Rows and Columns in train data\n",
    "print('shape of train data after preprocessing: {}'.format(ab_train.shape))\n",
    "print('shape of amenities train data after preprocessing: {}'.format(amenities_train.shape))\n",
    "print('shape of test data after preprocessing: {}'.format(ab_test.shape))\n",
    "print('shape of amenities test data after preprocessing: {}'.format(amenities_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of whole train data after concating: (49999, 175)\n",
      "shape of whole test data after concating: (24111, 174)\n"
     ]
    }
   ],
   "source": [
    "# combining the amenities with other features of ab_train\n",
    "train_ab=pd.concat([ab_train,amenities_train],axis=1)\n",
    "print('shape of whole train data after concating: {}'.format(train_ab.shape))\n",
    "\n",
    "test_ab=pd.concat([ab_test,amenities_test],axis=1)\n",
    "print('shape of whole test data after concating: {}'.format(test_ab.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_train: (49999, 173)\n",
      "shape of x_train: (49999,)\n",
      "shape of x_test: (24111, 173)\n"
     ]
    }
   ],
   "source": [
    "#### Separating independent and dependent features\n",
    "\n",
    "x_train=train_ab.drop(['id','log_price'],axis=1)\n",
    "y_train=train_ab['log_price']\n",
    "\n",
    "print('shape of y_train: {}'.format(x_train.shape))\n",
    "print('shape of x_train: {}'.format(y_train.shape))\n",
    "\n",
    "x_test=test_ab.drop(['id'],axis=1)\n",
    "\n",
    "print('shape of x_test: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I choose to build XGBoost as my final Machine Learing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Machine Learning: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "xgb_model=XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.4, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=5, reg_lambda=1, scale_pos_weight=3, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model=XGBRegressor(**{'colsample_bytree': 0.6, 'gamma': 0.4, 'learning_rate': 0.01, \n",
    "                          'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 1000, \n",
    "                          'reg_alpha': 5, 'scale_pos_weight': 3, 'subsample': 0.8})\n",
    "xgb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict=xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({'id':ab_test['id'],'log_price':test_predict})\n",
    "submissions.to_excel('test__ML_price.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5979389</td>\n",
       "      <td>4.084634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13488121</td>\n",
       "      <td>4.903500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8121643</td>\n",
       "      <td>4.921487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16490010</td>\n",
       "      <td>4.403557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16274069</td>\n",
       "      <td>5.014755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price\n",
       "0   5979389   4.084634\n",
       "1  13488121   4.903500\n",
       "2   8121643   4.921487\n",
       "3  16490010   4.403557\n",
       "4  16274069   5.014755"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Deep learning: Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep neural network\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               22272     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 187,137\n",
      "Trainable params: 187,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model=Sequential()\n",
    "\n",
    "# Input layer:\n",
    "NN_model.add(Dense(128,kernel_initializer='normal',input_dim=x_train.shape[1],activation='relu'))\n",
    "\n",
    "# Hidden layers:\n",
    "NN_model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dropout(rate=0.2))\n",
    "NN_model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dropout(rate=0.2))\n",
    "NN_model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# output layer:\n",
    "NN_model.add(Dense(1,kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# Compile the network\n",
    "NN_model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mean_squared_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "\n",
    "checkpoint_name='weights-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
    "checkpoint=ModelCheckpoint(checkpoint_name,monitor='val_loss',verbose=1,save_best_only=True,\n",
    "                          mode='auto')\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.3248 - mean_squared_error: 1.3248 - val_loss: 0.2032 - val_mean_squared_error: 0.2032\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20316, saving model to weights-001--0.20316.hdf5\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.2668 - mean_squared_error: 0.2668 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20316\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.2400 - mean_squared_error: 0.2400 - val_loss: 0.1973 - val_mean_squared_error: 0.1973\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20316 to 0.19728, saving model to weights-003--0.19728.hdf5\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.2145 - mean_squared_error: 0.2145 - val_loss: 0.1935 - val_mean_squared_error: 0.1935\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19728 to 0.19350, saving model to weights-004--0.19350.hdf5\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.2062 - mean_squared_error: 0.2062 - val_loss: 0.1940 - val_mean_squared_error: 0.1940\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19350\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.1912 - mean_squared_error: 0.1912 - val_loss: 0.1930 - val_mean_squared_error: 0.1930\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19350 to 0.19305, saving model to weights-006--0.19305.hdf5\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.1846 - mean_squared_error: 0.1846 - val_loss: 0.1998 - val_mean_squared_error: 0.1998\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19305\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.1807 - mean_squared_error: 0.1807 - val_loss: 0.1946 - val_mean_squared_error: 0.1946\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19305\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 21s 16ms/step - loss: 0.1785 - mean_squared_error: 0.1785 - val_loss: 0.2156 - val_mean_squared_error: 0.2156\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19305\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.1893 - val_mean_squared_error: 0.1893\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19305 to 0.18933, saving model to weights-010--0.18933.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5c1418070>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "NN_model.fit(x_train,y_train.values,epochs=10,validation_split=0.2,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_NN=NN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({'id':ab_test['id'],'log_price':test_predict_NN[:,0]})\n",
    "submission.to_excel('test_NN_price.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5979389</td>\n",
       "      <td>4.376175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13488121</td>\n",
       "      <td>4.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8121643</td>\n",
       "      <td>4.881930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16490010</td>\n",
       "      <td>4.527690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16274069</td>\n",
       "      <td>5.119294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price\n",
       "0   5979389   4.376175\n",
       "1  13488121   4.996700\n",
       "2   8121643   4.881930\n",
       "3  16490010   4.527690\n",
       "4  16274069   5.119294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
